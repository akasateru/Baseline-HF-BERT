{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline-HF-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForSequenceClassification, logging\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import wordnet\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "import datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "logging.set_verbosity_error()\n",
    "logging.set_verbosity_warning()\n",
    "HF_HUB_DISABLE_SYMLINKS_WARNING = True\n",
    "\n",
    "import datetime\n",
    "t_delta = datetime.timedelta(hours=9)\n",
    "JST = datetime.timezone(t_delta, 'JST')\n",
    "now = datetime.datetime.now(JST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "MODEL = \"bert-base-uncased\"\n",
    "# X_TRAIN = '../dataset/HF-BERT_x_train.npy'\n",
    "# Y_TRAIN = '../dataset/HF-BERT_y_train.npy'\n",
    "# X_TEST = '../dataset/HF-BERT_x_test.npy'\n",
    "# Y_TEST = '../dataset/HF-BERT_y_test.npy'\n",
    "SAVED_MODEL = \"../model/Baseline-HF-BERT_\"+str(now.strftime('%Y%m%d%H%M%S'))\n",
    "EPOCH = 2\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../model/Baseline-HF-BERT_20221122110116\n"
     ]
    }
   ],
   "source": [
    "print(SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "def preprocessing(text):\n",
    "    # 括弧内文章の削除\n",
    "    text = re.sub(r'\\(.*\\)',' ',text)\n",
    "    text = re.sub(r'\\[.*\\]',' ',text)\n",
    "    text = re.sub(r'\\<.*\\>',' ',text)\n",
    "    text = re.sub(r'\\{.*\\}',' ',text)\n",
    "    # 記号文字の削除\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    # スペースの調整\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making train dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 17091.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing train data -----------------------------------------------------------------------\n",
    "# load topic class labels\n",
    "print(\"making train dataset...\")\n",
    "with open('../data/topic/classes.txt','r',encoding='utf-8') as f:\n",
    "    labels = f.read().splitlines()\n",
    "topic_class_hypothesis = dict()\n",
    "for i,label in enumerate(labels):\n",
    "    topic_class_hypothesis[i] = 'this text is about ' + ' or '.join([wordnet.synsets(word)[0].definition() for word in label.split(' & ')])\n",
    "\n",
    "# load train data\n",
    "with open('../data/topic/train_pu_half_v0.txt','r',encoding='utf-8') as f:\n",
    "    texts_v0 = f.read()\n",
    "with open('../data/topic/train_pu_half_v1.txt','r',encoding='utf-8') as f:\n",
    "    texts_v1 = f.read()\n",
    "texts = texts_v0 + texts_v1\n",
    "\n",
    "# ## example -------------------------------------\n",
    "import random\n",
    "texts = texts.splitlines()\n",
    "texts = random.sample(texts,1000)\n",
    "texts = \"\\n\".join(texts)\n",
    "# ## ---------------------------------------------\n",
    "\n",
    "x_train, y_train = [],[]\n",
    "train_first, train_second = [],[]\n",
    "for label_text in tqdm(texts.splitlines()):\n",
    "    label,text = label_text.split('\\t')\n",
    "    rand_base = [0,1,2,3,4,5,6,7,8,9]\n",
    "    rand_base.remove(int(label))\n",
    "    label_rand = np.random.choice(rand_base)\n",
    "    train_first.append(preprocessing(text))\n",
    "    train_second.append(topic_class_hypothesis[int(label)])\n",
    "    y_train.append(float(1))\n",
    "    train_first.append(preprocessing(text))\n",
    "    train_second.append(topic_class_hypothesis[int(label_rand)])\n",
    "    y_train.append(float(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5376.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# dbpedia class ------------------------------------------------------------------------------------------------------\n",
    "with open('../data/dbpedia_csv/classes.txt','r',encoding='utf-8') as f:\n",
    "    classes = f.read().splitlines()\n",
    "    dbpedia_class = ['this text is about '+text for text in classes]\n",
    "\n",
    "with open('../data/dbpedia_csv/test.csv','r',encoding='utf-8') as f:\n",
    "    reader = [r for r in csv.reader(f)]\n",
    "    \n",
    "# # example -------------------\n",
    "import random\n",
    "reader = random.sample(reader,1000)\n",
    "# #----------------------------\n",
    "\n",
    "x_test, y_test = [],[]\n",
    "test_first, test_second = [],[]\n",
    "for cls_num,auth,readtext in tqdm(reader,total=len(reader)):\n",
    "    for db_class in dbpedia_class:\n",
    "        text = readtext.replace(auth, \"\")\n",
    "        test_first.append(preprocessing(text))\n",
    "        test_second.append(db_class)\n",
    "    y_test.append(int(cls_num)-1)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dce9e5facba4dab9292bc8c10e7c7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf8f89e8d1e41f0ad703f1b04b3d112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 14000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "train_dataset = datasets.Dataset.from_dict({\"first\":train_first, \"second\":train_second, \"label\":y_train})\n",
    "test_dataset = datasets.Dataset.from_dict({\"first\":test_first, \"second\":test_second})\n",
    "dataset = datasets.DatasetDict({\"train\":train_dataset, \"test\":test_dataset})\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"first\"], examples[\"second\"], truncation=True, return_tensors=\"pt\", padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns('first').remove_columns(\"second\")\n",
    "print(tokenized_datasets)\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42) #.select(range(5000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"] #.select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.where(0.5<=logits.squeeze(), 1, 0)\n",
    "    return evaluate.load(\"accuracy\").compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=SAVED_MODEL,\n",
    "  num_train_epochs=EPOCH,\n",
    "  per_device_train_batch_size=BATCH_SIZE,\n",
    "  per_device_eval_batch_size=BATCH_SIZE,\n",
    "  evaluation_strategy=\"epoch\",\n",
    "  optim=\"adamw_torch\",\n",
    "  report_to=\"none\"\n",
    "  )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_train_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cab7a8c35b46a8b9aeb9f9eb89df9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a734f77d6a04894968172e64fbecc9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07591088116168976, 'eval_accuracy': 0.9015, 'eval_runtime': 44.6923, 'eval_samples_per_second': 44.75, 'eval_steps_per_second': 5.594, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../model/Baseline-HF-BERT_20221122110116\\checkpoint-500\n",
      "Configuration saved in ../model/Baseline-HF-BERT_20221122110116\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1433, 'learning_rate': 0.0, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../model/Baseline-HF-BERT_20221122110116\\checkpoint-500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9201f9fdb224712b0447cb06ec806b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.04599885642528534, 'eval_accuracy': 0.9415, 'eval_runtime': 49.2684, 'eval_samples_per_second': 40.594, 'eval_steps_per_second': 5.074, 'epoch': 2.0}\n",
      "{'train_runtime': 391.1323, 'train_samples_per_second': 10.227, 'train_steps_per_second': 1.278, 'train_loss': 0.14325254821777345, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=500, training_loss=0.14325254821777345, metrics={'train_runtime': 391.1323, 'train_samples_per_second': 10.227, 'train_steps_per_second': 1.278, 'train_loss': 0.14325254821777345, 'epoch': 2.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../model/Baseline-HF-BERT_20221122110116\\config.json\n",
      "Model weights saved in ../model/Baseline-HF-BERT_20221122110116\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../model/Baseline-HF-BERT_20221122110116\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../model/Baseline-HF-BERT_20221122110116\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../model/Baseline-HF-BERT_20221122110116\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../model/Baseline-HF-BERT_20221122110116.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(SAVED_MODEL)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=SAVED_MODEL,report_to=\"none\")\n",
    "trainer = Trainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 14000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c712b0f72364a4cb6d0d60b256e648d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(small_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Com.      0.631     0.679     0.654        78\n",
      "        Edu.      0.624     0.986     0.764        74\n",
      "        Art.      0.238     0.338     0.279        71\n",
      "        Ath.      0.931     0.971     0.950        69\n",
      "        Off.      0.902     0.613     0.730        75\n",
      "        Mea.      0.759     0.344     0.473        64\n",
      "        Bui.      0.767     0.667     0.713        69\n",
      "        Nat.      0.877     0.842     0.859        76\n",
      "        Vil.      0.812     0.986     0.890        70\n",
      "        Ani.      0.929     0.574     0.709        68\n",
      "        Pla.      0.615     1.000     0.762        72\n",
      "        Alb.      0.600     0.167     0.261        72\n",
      "        Fil.      0.823     0.942     0.878        69\n",
      "        Wri.      0.571     0.548     0.559        73\n",
      "\n",
      "    accuracy                          0.692      1000\n",
      "   macro avg      0.720     0.690     0.677      1000\n",
      "weighted avg      0.718     0.692     0.678      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# y_pred = [np.argmax(i) for i in pred.predictions]\n",
    "\n",
    "# rep = classification_report(y_test, y_pred, target_names=target_names, digits=3)\n",
    "# print(rep)\n",
    "\n",
    "split_pred = np.array_split(pred.predictions,len(y_test))\n",
    "y_pred = [np.argmax(p) for p in split_pred]\n",
    "\n",
    "target_names = [c[:3]+\".\" for c in classes]\n",
    "rep = metrics.classification_report(y_test,y_pred,target_names=target_names,digits=3)\n",
    "print(rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e32349538976b425bbf8209bec3a52ef38eb988b8b568d4d0fb100f86dbbec2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
